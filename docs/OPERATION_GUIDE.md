# Operation Guide

> [!NOTE]
> **Derni√®re mise √† jour** : 2026-02-22 ‚Äî Phase 2.A termin√©e. Backend op√©rationnel.

---

## 0. Commandes Essentielles (√âtat Syst√®me)

```bash
# √âtat des containers
docker compose ps

# Logs worker (ingestion en cours)
docker logs -n 50 supervision_worker

# Logs backend (API)
docker logs -n 50 supervision_backend

# Compter les √©v√©nements en DB
docker compose exec db psql -U admin -d supervision -c "SELECT COUNT(*) FROM events;"

# Compter les raccordements par provider
docker compose exec db psql -U admin -d supervision -c \
  "SELECT p.code, COUNT(s.id) AS sites FROM monitoring_providers p LEFT JOIN site_connections s ON p.id = s.provider_id GROUP BY p.code;"

# √âtat des imports
docker compose exec db psql -U admin -d supervision -c \
  "SELECT status, COUNT(*) FROM imports GROUP BY status;"
```

---

## 0.B Proc√©dure d'Ingestion Manuelle

> [!IMPORTANT]
> Suivre ces √©tapes dans l'ordre pour valider une ingestion end-to-end.

1. **D√©poser le fichier** dans le r√©pertoire d'ingress :
   - Via Dropbox : copier le `.xls` dans `./dropbox_in/`
   - Via IMAP : envoyer l'email avec pi√®ce jointe √† l'adresse configur√©e

### Gestion des Providers (Phase 2.A & 2.B)

Les providers (t√©l√©surveilleurs) peuvent √™tre configur√©s via l'interface Admin ou directement via l'API.

#### Param√©trage du Monitoring (Phase 2.B)
Pour chaque provider, vous pouvez d√©finir :
- **Seuil de silence** : D√©lai max (en minutes) sans r√©ception avant alerte.
- **Volume attendu** : Nombre d'imports pr√©vus par 24h.
- **Email de secours** : Contact pour les notifications de sant√© du flux.

#### Ajout d'une r√®gle SMTP
Pour affecter automatiquement un mail entrant √† un provider :
1. Aller dans **Admin > SMTP Rules**.
2. Ajouter une r√®gle (ex: Type `DOMAIN`, Valeur `beta-telecom.fr`).
3. D√©finir la priorit√© (plus c'est haut, plus c'est test√© t√¥t).

2. **V√©rifier que l'import est trait√©** :
   ```bash
   docker logs -f supervision_worker 2>&1 | grep -E "SUCCESS|ERROR|import_"
   ```
   Attendre le message : `event=import_complete status=SUCCESS`

3. **Contr√¥ler les √©v√©nements ins√©r√©s** :
   ```bash
   docker compose exec db psql -U admin -d supervision -c "SELECT COUNT(*) FROM events;"
   ```
   R√©sultat attendu : `> 0`

4. **V√©rifier l'incr√©mentation des raccordements** :
   ```bash
   docker compose exec db psql -U admin -d supervision -c \
     "SELECT code_site, total_events, last_seen_at FROM site_connections ORDER BY last_seen_at DESC LIMIT 10;"
   ```

5. **Valider la classification du provider** :
   ```bash
   docker compose exec db psql -U admin -d supervision -c \
     "SELECT p.code, i.id, i.status FROM imports i JOIN monitoring_providers p ON i.provider_id = p.id ORDER BY i.created_at DESC LIMIT 5;"
   ```

---

## 1. Deployment & Lifecycle

### Start Stack
```bash
docker compose up -d --build
```
*Wait for TimescaleDB to initialize (approx 20s on first run).*

### Stop Stack
```bash
docker compose down
```

### Restart Helper
To restart only the backend logic (code reload):
```bash
docker compose restart backend worker
```

## 2. Database Management

### Database Access
```bash
docker compose exec db psql -U admin -d supervision
```

### Backup
A script `backup_before_migration.sql` is available.
Manually:
```bash
docker compose exec db pg_dump -U admin supervision > backup_$(date +%F).sql
```

### Migrations
Les migrations sont g√©r√©es automatiquement au d√©marrage, mais peuvent √™tre rejou√©es manuellement :
```bash
docker exec -i supervision_db psql -U admin -d supervision < backend/migrations/15_sliding_window_sequences.sql
docker exec -i supervision_db psql -U admin -d supervision < backend/migrations/12_rule_conditions.sql
```

### Seed & Donn√©es de Test (Alerting V3)
Pour valider le moteur d'alerte avec des sc√©narios r√©els (S√©quences, AST) :
```bash
docker exec -i supervision_db psql -U admin -d supervision < backend/migrations/16_seed_test_rules.sql
```
*Cela injecte 4 types de r√®gles (Simple, OpenOnly, Sequence, AST) pour la v√©rification.*

## 3. Gestion de l'Acc√®s Admin (S√©curit√©)

### Seed Automatique au D√©marrage
Le syst√®me v√©rifie au boot s'il existe au moins un utilisateur avec le r√¥le `ADMIN`.
- **En D√©veloppement** (`ENVIRONMENT=development`) : Si absent, un admin est cr√©√© avec `admin@supervision.local / SuperSecurePassword123`. Les tables sont cr√©√©es automatiquement (`create_all`).
- **En Production** (`ENVIRONMENT=production`) :
  - L'auto-seed ne s'ex√©cute **que si la table `users` existe** (migrations compl√©t√©es).
  - Le mot de passe **doit** √™tre d√©fini via la variable d'environnement `DEFAULT_ADMIN_PASSWORD`.
  - La cr√©ation de table automatique est **d√©sactiv√©e`.

### Variables d'Environnement Cl√©s
| Variable | Valeur par d√©faut | Description |
|---|---|---|
| `ENVIRONMENT` | `production` | `production` ou `development`. |
| `DEFAULT_ADMIN_EMAIL` | `admin@supervision.local` | Email de l'admin par d√©faut. |
| `DEFAULT_ADMIN_PASSWORD` | *(Aucune en prod)* | **Obligatoire en production** pour le seed initial. |
| `AUTO_SEED_ADMIN` | `True` | D√©sactiver pour emp√™cher tout auto-seed. |

### Monitoring des Providers (Phase 2.B)

Les colonnes de monitoring dans `monitoring_providers` sont configur√©es avec des valeurs par d√©faut strictes pour √©viter les erreurs d'insertion :
- `expected_emails_per_day` : 0
- `expected_frequency_type` : 'daily'
- `silence_threshold_minutes` : 1440 (24h)
- `monitoring_enabled` : false
- `is_active` : true

#### V√©rification de la structure et des defaults
Pour v√©rifier que la base de donn√©es est correctement configur√©e :

```powershell
docker compose exec db psql -U admin -d supervision -c "SELECT column_name, is_nullable, column_default FROM information_schema.columns WHERE table_name='monitoring_providers' AND column_name IN ('expected_emails_per_day','expected_frequency_type','silence_threshold_minutes','monitoring_enabled','is_active');"
```

#### V√©rification des donn√©es
Pour lister les 5 derniers providers et leurs param√®tres de monitoring :

```powershell
docker compose exec db psql -U admin -d supervision -c "SELECT code, expected_emails_per_day, expected_frequency_type, silence_threshold_minutes, monitoring_enabled, is_active FROM monitoring_providers ORDER BY id DESC LIMIT 5;"
```
### Proc√©dure de Secours (D√©pannage Admin)
Si l'acc√®s Admin est perdu ou si le password doit √™tre forc√© depuis le serveur :
```bash
docker compose exec backend python create_admin.py --email "votre@email.com" --password "NouveauPasswordSecurise"
```
*Cette commande est prioritaire sur l'auto-seed et mettra √† jour l'utilisateur s'il existe d√©j√†.*

---

## 4. Maintenance Database (Protections)

### Synchronisation des Tables (`sync_db.py`)
Le script `sync_db.py` (qui ex√©cute `create_all`) est **verrouill√© en production** pour √©viter tout reset accidentel.

Pour outrepasser cette s√©curit√© (usage exceptionnel) :
```bash
docker compose exec -e ALLOW_SYNC_DB=1 -e I_UNDERSTAND_DATA_LOSS=YES backend python sync_db.py
```

## 5. Monitoring & Debugging

### View Logs
```bash
docker logs -f supervision_worker    # Ingestion logs
docker logs -f supervision_backend   # API logs
```

### Ingestion Health Dashboard (Roadmap 5)
A synthetic dashboard is available on the main landing page to monitor ingestion health in real-time.

#### Health Status Legend
- üü¢ **OK**: All expected files received, events ingested, and integrity >= 95%.
- üü° **WARNING**: Integrity dropped below 95% OR PDF support files are missing for some XLS imports.
- üî¥ **CRITICAL**: No XLS files received for the day OR zero events ingested (potential parser failure).

#### API Endpoint
- `GET /api/v1/health/ingestion-summary`: Returns today's metrics aggregated by provider.
- *Dependencies*: Requires Administrator role.
- *Refresh Rate*: UI auto-refreshes every 60 seconds.

### Rule Trigger Monitoring (Roadmap 6)
Monitoring des d√©clenchements de r√®gles d'alertes en temps r√©el.

#### Seuils d'Activit√© (config.yml)
Les statuts sont calcul√©s selon des seuils modifiables dans `backend/config.yml` :
- `RULE_MONITORING_HIGH_THRESHOLD` (d√©faut: 100) -> üî¥ **HIGH**
- `RULE_MONITORING_LOW_THRESHOLD` (d√©faut: 1) -> üü° **LOW**

#### Drildown
Le clic sur une r√®gle dans le dashboard redirige vers la page **Data Validation** pr√©-filtr√©e sur cette r√®gle pour une analyse d√©taill√©e des √©v√©nements.

#### API Endpoint
- `GET /api/v1/rules/trigger-summary?date=YYYY-MM-DD`
- *Dependencies*: Requires Administrator role.

#### Structured Logs (Roadmap 4)
Recherchez ces tags pour valider l'ingestion :
- `[Ingestion] ATTACHMENT_RECEIVED`: Nouveau fichier d√©tect√©.
- `[Ingestion] FILTER_DECISION`: ACCEPT/IGNORED (v√©rifie le format).
- `[Ingestion] PAIR_ATTEMPT`: Tentative de liaison PDF <-> XLS.
- `[Ingestion] PDF_SUPPORT_WRITTEN`: Confirmation de l'√©criture des m√©tadonn√©es PDF.
- `[Resolver] MATCH/FALLBACK`: D√©tails de l'identification du provider.

### Navigation & Audit (Import Log)
L'interface de validation des donn√©es permet de naviguer dans l'historique complet des imports :
- **Pagination** : La liste des imports est pagin√©e (serveur) pour garantir la fluidit√©.
- **Filtres** : Recherche par statut (SUCCESS/ERROR) et plage de dates.
- **Colonnes (Visibilit√© / Ordre)** : Personnalisez votre vue en masquant/r√©ordonnant les colonnes via le menu DataGrid. Ces r√©glages persistent localement dans votre navigateur.
- **Colonnes (Largeur)** : Les largeurs ont √©t√© optimis√©es manuellement pour offrir une lecture confortable sans troncature excessive. Le d√©filement horizontal s'active automatiquement pour les contenus longs (ex: messages techniques). *Note : Le redimensionnement interactif √† la souris n'est pas disponible dans la version Community actuelle.*
- **Audit** : Le compteur total permet de suivre le volume d'activit√©.

### D√©tails d'un Import (√âv√©nements)
Lorsque vous cliquez sur un import, la liste des √©v√©nements s'affiche avec des informations enrichies pour l'analyse m√©tier :
- **Action** : Affiche le type d'√©v√©nement (`APPARITION` en rouge, `DISPARITION` en vert). Cela permet de rep√©rer imm√©diatement les cycles d'alertes.
- **Code** : Affiche le code d'alarme ou de transmission brut (ex: `MVS`, `130`, `SMAIL`) issu directement du fichier source.
- **Filtres Rapides** : Utilisez les champs "Filtre Action" et "Filtre Code" en haut du tableau pour isoler instantan√©ment des √©v√©nements sur la page charg√©e.
- **Persistance** : Comme pour la table principale, la visibilit√© et l'ordre des colonnes sont m√©moris√©s dans votre navigateur.

## 5. Storage & Uploads (V2.5)

### Locations
- **Photos de profil** : Stock√©es dans `/app/data/uploads` sur le serveur.
- **Acc√®s** : Servies via http://localhost:8000/uploads/

### Persistence (Docker)
Pour ne pas perdre les photos au red√©marrage, assurez-vous que le volume suivant est pr√©sent dans `docker-compose.yml` :
```yaml
services:
  backend:
    volumes:
      - ./data/uploads:/app/data/uploads
```

### Procedures
- **Backup** : Copiez le dossier `./data/uploads` lors de vos sauvegardes r√©guli√®res.
- **Vider le cache** : Les fichiers sont renomm√©s avec un timestamp (`user_{id}_{timestamp}.png`), ce qui √©vite les probl√®mes de cache navigateur.

## 6. Data Architecture & Persistence

### Code vs. Runtime Data
The repository follows a strict separation between application code and runtime data/backups:
- **Git Tracked**: Code, migrations, configuration templates, and `docker/seed.sql`.
- **Git Ignored**: `docker/data/` (Postgres/Redis volumes), `backups/`, `archive/`, `dropbox_in/`.

> [!WARNING]
> Never force-add `docker/data/` to Git. This folder contains a live Postgres instance and is platform-dependent.

### Docker Volumes
On a VPS or Production environment, data persistence is handled via Docker volumes mapped to host folders:
- `./docker/data/db` -> Postgres storage.
- `./archive` -> Permanent storage for ingested files.
- `./backups` -> Local dump storage (should be symlinked to a large external drive if possible).

## 7. Backup & Restore Strategy (Production)

### Strategy
1. **Database**: Daily logical dumps using `pg_dump`.
2. **Files**: Incremental rsync of the `archive/` folder to an offsite location (e.g., S3, OVH Cloud Archive).

### Restore to a fresh VPS
1. Clone the repo.
2. Initialize the DB structure using the seed:
   ```bash
   docker compose up -d db
   docker compose exec -T db psql -U admin -d supervision < docker/seed.sql
   ```
3. Restore the latest data dump:
   ```bash
   docker compose exec -T db psql -U admin -d supervision < latest_dump.sql
   ```
4. Restore the `archive/` folder from backup.

## 8. KNOWN ISSUES & TROUBLESHOOTING

| Symptom | Cause | Solution | Lesson |
| :--- | :--- | :--- | :--- |
| **Worker Crash with "ImportError"** | Circular dependency in `config.py` vs `config_loader.py`. | Moved imports to top-level or inside functions to break the cycle. | Keep configuration loading simple and acyclic. |
| **Docker: `02_normalization.sql` not found** | Windows file system vs Linux Docker volume mounting. | Embedded the SQL script directly into the Python migration runner. | Avoid relying on complex volume binds for initialization scripts on Windows. |
| **API 500 Error on GET** | Pydantic V2 strictness on ORM objects. | Added `model_config = ConfigDict(from_attributes=True)` to schemas. | Pydantic V2 requires explicit opt-in for ORM mode. |
| **100% Events Marked Duplicate** | Deduplication used `time.time()` (Processing Time) vs `event.timestamp`. | Changed Dedupe key to use Event Timestamp Bucket. | Idempotence must rely on deterministic data, not processing time. |
| **UI: Zebra Striping Broken** | Default MUI CSS specificity was higher than custom class. | Used `sx` prop or `!important` utility classes correctly. | Ensure custom theme classes have sufficient specificity. |
| **Site Code contains "C-"** | Raw data often has prefixes (e.g., `C-69000`). | added Regex `\D` replacement in Normalizer. | Always sanitize identifiers (Digits Only) before storage. |
| **Frontend build broken** | Relative import `../../../utils/api` in generic pages. | Always use the alias `@/lib/api`. | Leverage TS paths for cleaner and more robust imports. |
| **DB Reset in Production** | `create_all` called on every boot in older versions. | Hard locking of `create_all` if `ENVIRONMENT != development`. | Production DB schema must only change via migrations. |
| **Emails "Lost"** | Missing keyword or invalid format. | Check `ImportLog` with status `IGNORED`. | Traceability is key for debugging ingestion pipelines. |

---

## Roadmap 2.A ‚Äî Business Metrics Layer

### Aper√ßu
La Phase 2.A ajoute le comptage automatique des raccordements (codes site distincts) par t√©l√©surveilleur, avec classification SMTP dynamique.

### Migrations SQL (ordre d'ex√©cution)

```powershell
# 1. Enrichissement de site_connections (last_seen_at, total_events)
Get-Content backend/migrations/17_business_counter_updates.sql | docker exec -i supervision_db psql -U admin -d supervision

# 2. Seed des providers g√©n√©riques
Get-Content backend/migrations/18_seed_providers.sql | docker exec -i supervision_db psql -U admin -d supervision
```

> [!IMPORTANT]
> Ces migrations sont **strictement non-destructives** (`ADD COLUMN IF NOT EXISTS`, `ON CONFLICT DO NOTHING/UPDATE`). Elles peuvent √™tre rejou√©es sans risque.

### Commandes de maintenance

```bash
# Lister les providers actifs
docker exec supervision_db psql -U admin -d supervision -c "SELECT code, label FROM monitoring_providers WHERE is_active = true;"

# Voir les r√®gles SMTP actives (par priorit√©)
docker exec supervision_db psql -U admin -d supervision -c "SELECT p.code, r.match_type, r.match_value, r.priority FROM smtp_provider_rules r JOIN monitoring_providers p ON r.provider_id = p.id WHERE r.is_active = true ORDER BY r.priority;"

# Contr√¥le des compteurs de raccordements
docker exec supervision_db psql -U admin -d supervision -c "SELECT p.code, count(s.id) AS sites, sum(s.total_events) AS events FROM monitoring_providers p LEFT JOIN site_connections s ON p.id = s.provider_id GROUP BY p.code;"
```

### Ajouter une r√®gle de classification SMTP

```bash
# Exemple : tous les emails du domaine @example.org ‚Üí PROVIDER_ALPHA
docker exec supervision_db psql -U admin -d supervision -c "
INSERT INTO smtp_provider_rules (provider_id, match_type, match_value, priority, is_active)
SELECT id, 'DOMAIN', 'example.org', 15, true
FROM monitoring_providers WHERE code = 'PROVIDER_ALPHA'
ON CONFLICT DO NOTHING;"
```

### API Endpoints Business

| M√©thode | URL | Description |
|---|---|---|
| `GET` | `/api/v1/admin/business/summary` | Totaux par provider |
| `GET` | `/api/v1/admin/business/timeseries?granularity=month` | Nouveaux raccordements par mois |
| `GET` | `/api/v1/admin/business/sites?page=1&size=50` | Drilldown pagin√© |
| `GET` | `/api/v1/admin/business/smtp-rules` | Liste des r√®gles SMTP |

### Tester la suite business

```bash
# Tests unitaires (classification SMTP avec mocks)
docker compose exec -w /app backend python -m pytest tests/test_business_counter.py -v -k "not integration"
```

### UI Admin

Accessible dans l'interface admin : **Admin ‚Üí M√©triques Business**
- Route : `/admin/business-metrics`
- Contenu : 4 widgets de synth√®se, graphique d'√©volution, table drilldown pagin√©e

### Fallback obligatoire

Si aucune r√®gle SMTP ne matche l'exp√©diteur, l'import est automatiquement attribu√© au provider `PROVIDER_UNCLASSIFIED`. Ce provider **doit toujours exister** en base (inclus dans `18_seed_providers.sql`).
